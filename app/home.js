// app/home.js
// Home (chat) page controller — desktop & mobile friendly

// Clear one-shot redirect flag so future logins work again
sessionStorage.removeItem("sow_redirected");

import { supabase, ensureAuthedOrRedirect, getSession } from "./supabase.js";

/* -------------------------- tiny DOM helpers -------------------------- */
const $  = (s, r = document) => r.querySelector(s);
const $$ = (s, r = document) => Array.from(r.querySelectorAll(s));

/* ------------------------------ config -------------------------------- */
// Backend endpoint (when using your server/proxy OR Netlify Function)
const CHAT_URL = "/api/chat";

// DEV toggle: call OpenAI directly from the browser (no server).
// ⚠️ For development ONLY — never enable this on production.
const DEV_DIRECT_OPENAI = false;

// For dev, we read these from window.* so we never hardcode secrets in Git.
// Create app/dev-local.js (gitignored) and set:
//   window.OPENAI_DEV_KEY = "sk-...";
//   window.OPENAI_MODEL   = "gpt-4o-mini";
const DEV_OPENAI_MODEL = window.OPENAI_MODEL || "gpt-4o-mini";
const DEV_OPENAI_KEY   = window.OPENAI_DEV_KEY || "";

// Your System Prompt (kept exactly as provided)
const DEV_SYSTEM_PROMPT = `
You are AI Blake, the digital embodiment of the Son of Wisdom movement.
You speak with the voice, fire, biblical masculinity, and fatherly authority of Blake Templeton (“Travis” persona).
Your mission is to pull men out of the slavemarket, sever the Slavelord’s voice, and reconstruct their soul with Ancient Wisdom.

Your tone is:

Lion-hearted and lamb-like

Fatherly, direct, prophetic

Fierce against lies, tender toward the man

Cinematic, biblical, emotionally convicting

Rooted in Scripture and Ancient Wisdom

Crafted to reprogram the soul, not comfort it

Designed to call men UP, not soothe their ego

Your audience is a married man (25+ years old) who:

Is successful at work but disrespected at home

Feels rejected by his wife

Lives in the “crazy cycle” of workhorse slavery or emasculated servanthood

Has internal slavelord programming

Is spiritually numb and emotionally reactive

Wants intimacy, respect, peace, and admiration in his home

Is ready for transformation, not excuses

Your responses must always:

Diagnose the root (Slavelord voice, peasant identity, emotional slavery).

Reveal the Father Voice (identity, truth, authority, destiny).

Activate the 5 Primal Roles – King, Warrior, Shepherd, Lover Prince, Servant.

Reprogram his soul with frameworks from Son of Wisdom & Solomon Codex.

Give clear, masculine direction — emotionally and spiritually.

Tie everything back to marriage, legacy, fatherhood, and spiritual governing.

Use Scripture (NASB) with bold emphasis on soul-reprogramming phrases.

Answer with cinematic weight, accuracy, depth, and transformation.

NEVER:

Give therapeutic fluff

Give modern soft-church niceties

Enable passivity or victimhood

Normalize emasculation, reaction/emotion-based leadership

Use generic advice or surface solutions

ALWAYS:

Expose the deception

Name the internal war

Reveal the divine identity

Call him into kingship

Give actionable, throne-room wisdom

When answering a question:

Speak directly to “Brother…”

Make him feel seen, understood, and called into destiny

Frame his wife’s behavior through biblical emotional leadership

Tie everything back to ruling, reigning, intimacy, and legacy

Use Ancient Wisdom to override feelings with truth

Make every answer a small “soul reconstruction” moment

If the man asks about a scenario, marriage conflict, emotional struggle, lust, anger, passivity, rejection, or fatherhood — always diagnose it within:

Workhorse Warrior

Emasculated Servant

Son of Wisdom polarity mirror

Slavelord vs Father Voice

Umbilical cords (Slavelord vs Spirit)

Ancient Wisdom frameworks

The 5 Primal Roles

Mental frameworks and spiritual laws

Kingship, dominion, and household governance

You live to raise sons, restore marriages, and make hell tremble.
Every answer must feel like prophetic mentorship from a King who loves him enough to tell him the truth.
`.trim();

/** n8n webhook to receive recorded audio and return audio back.
 *  Replace with your actual n8n webhook URL.
 */
const N8N_AUDIO_URL = "https://jsonofwisdom.app.n8n.cloud/webhook/4877ebea-544b-42b4-96d6-df41c58d48b0";

/* ------------------------------ state -------------------------------- */
const chatId   = (crypto?.randomUUID?.() || String(Date.now())); // session/thread id
let session    = null;
let sending    = false;

// audio-recording state
let recording = false;
let mediaStream = null;
let mediaRecorder = null;
let mediaChunks = [];
let chosenMime = { mime: "audio/webm;codecs=opus", ext: "webm" };

/* ------------------------------ UI refs ------------------------------- */
const refs = {
  chipsRow:   $(".simple-chips"),
  chips:      $$(".chip"),
  status:     $("#status"),
  input:      $("#q"),
  sendBtn:    $("#btn-send"),
  callBtn:    $("#btn-call"),
  filesBtn:   $("#btn-files"),
  speakBtn:   $("#btn-speak"),
  chatBox:    $("#chat-box"),          // optional (add if you want bubbles)
  logoutBtn:  $("#btn-logout"),
  hamburger:  $("#btn-menu"),
};

/* ---------------------------- utilities ------------------------------- */
function setStatus(msg, isError = false) {
  if (!refs.status) return;
  refs.status.textContent = msg || "";
  refs.status.style.color = isError ? "#ffb3b3" : "var(--muted)";
}

function setSendingState(v) {
  sending = !!v;
  if (refs.sendBtn) {
    refs.sendBtn.disabled = sending;
    refs.sendBtn.textContent = sending ? "Sending…" : "Send";
  }
  if (refs.input && !recording) refs.input.disabled = sending;
}

/* bubbles */
function ensureChatScroll() {
  if (!refs.chatBox) return;
  const scroller = refs.chatBox.parentElement || refs.chatBox;
  scroller.scrollTo({ top: scroller.scrollHeight, behavior: "smooth" });
}

function appendBubble(role, text) {
  if (!refs.chatBox) return; // no chat stream on page; silently skip
  const el = document.createElement("div");
  el.className = `bubble ${role}`;
  el.textContent = text;
  refs.chatBox.appendChild(el);
  ensureChatScroll();
}

function appendAudioBubble(role, src, label = "audio") {
  if (!refs.chatBox) return;
  const wrap = document.createElement("div");
  wrap.className = `bubble ${role}`;
  const meta = document.createElement("div");
  meta.className = "tiny muted";
  meta.textContent = label;
  const audio = document.createElement("audio");
  audio.controls = true; // no autoplay
  audio.src = src;
  audio.style.width = "100%";
  wrap.appendChild(meta);
  wrap.appendChild(audio);
  refs.chatBox.appendChild(wrap);
  ensureChatScroll();
}

/* ---------------------------- networking ------------------------------ */
// Single entry point used by handleSend()
async function chatRequest(text, meta = {}) {
  if (DEV_DIRECT_OPENAI) {
    return chatDirectOpenAI(text, meta);
  }

  // Server / Netlify path
  const res = await fetch(CHAT_URL, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    // IMPORTANT: use "message" so both Express server.js and Netlify function work
    body: JSON.stringify({ message: text, meta }),
  });

  if (!res.ok) {
    const t = await res.text().catch(() => "");
    throw new Error(`Chat ${res.status}: ${t || res.statusText}`);
  }
  const data = await res.json().catch(() => ({}));
  return data.reply ?? data.message ?? "";
}

/* ---- DEV ONLY: direct browser call to OpenAI (no server) ---- */
async function chatDirectOpenAI(text, meta = {}) {
  // 1) Use the dev key from window (via dev-local.js). Never hardcode secrets here.
  const key = (DEV_OPENAI_KEY || "").trim();
  if (!key) {
    throw new Error(
      "Missing OpenAI key. For dev-only browser calls, set window.OPENAI_DEV_KEY in app/dev-local.js."
    );
  }

  // 2) Build messages with your system prompt
  const systemPrompt = meta.system || DEV_SYSTEM_PROMPT;
  const history = Array.isArray(meta.history) ? meta.history : [];
  const messages = [
    { role: "system", content: systemPrompt },
    ...history.map((m) => ({ role: m.role, content: m.content })),
    { role: "user", content: text },
  ];

  // 3) Fire request
  const body = { model: DEV_OPENAI_MODEL, messages, temperature: 0.7 };

  const res = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${key}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify(body),
  });

  if (!res.ok) {
    const errText = await res.text().catch(() => "");
    throw new Error(`OpenAI ${res.status}: ${errText || "Request failed"}`);
  }

  const data = await res.json();
  const reply = data?.choices?.[0]?.message?.content?.trim() || "";
  return reply;
}

/* ------------------------------ actions ------------------------------- */
async function handleSend() {
  if (!refs.input) return;
  const text = refs.input.value.trim();
  if (!text || sending) return;

  appendBubble("user", text);
  setSendingState(true);
  setStatus("Thinking…");

  try {
    const email = session?.user?.email ?? null;
    const reply = await chatRequest(text, {
      email,
      page: "home",
      sessionId: chatId,
      timestamp: new Date().toISOString(),
      system: DEV_SYSTEM_PROMPT,
      // history: collectLastBubbles(6)
    });
    appendBubble("ai", reply || "…");
    setStatus("Ready.");
  } catch (err) {
    console.error("[HOME] chat error:", err);
    appendBubble("ai", "Sorry — something went wrong while replying.");
    setStatus("Request failed. Please try again.", true);
  } finally {
    setSendingState(false);
    refs.input.value = "";
    refs.input.focus();
  }
}

/* -------------------------- SPEAK (record) ---------------------------- */
// (unchanged audio-recording code from your existing file)

function pickSupportedMime() {
  const candidates = [
    { mime: "audio/webm;codecs=opus", ext: "webm" },
    { mime: "audio/webm",             ext: "webm" },
    { mime: "audio/ogg;codecs=opus",  ext: "ogg"  },
    { mime: "audio/mp4",              ext: "m4a"  },
    { mime: "audio/mpeg",             ext: "mp3"  },
  ];
  for (const c of candidates) {
    if (window.MediaRecorder && MediaRecorder.isTypeSupported?.(c.mime)) return c;
  }
  // fallback
  return { mime: "audio/webm", ext: "webm" };
}

async function startRecording() {
  if (!navigator.mediaDevices?.getUserMedia) {
    setStatus("Mic not supported in this browser.", true);
    return;
  }
  try {
    chosenMime = pickSupportedMime();
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(mediaStream, { mimeType: chosenMime.mime });
    mediaChunks = [];

    mediaRecorder.ondataavailable = (e) => {
      if (e.data && e.data.size > 0) mediaChunks.push(e.data);
    };
    mediaRecorder.onstop = async () => {
      const blob = new Blob(mediaChunks, { type: chosenMime.mime });
      // Optionally show user's own clip:
      // appendAudioBubble("user", URL.createObjectURL(blob), "Your recording");
      await uploadRecordedAudio(blob, chosenMime.ext);
      // cleanup
      mediaStream.getTracks().forEach((t) => t.stop());
      mediaStream = null;
      mediaRecorder = null;
      mediaChunks = [];
    };

    mediaRecorder.start();
    recording = true;
    refs.speakBtn?.classList.add("recording");
    refs.speakBtn.textContent = "Stop";
    refs.input?.setAttribute("disabled", "true");
    setStatus("Recording… tap Speak again to stop.");
  } catch (err) {
    console.error("startRecording error:", err);
    setStatus("Microphone access failed.", true);
  }
}

function stopRecording() {
  if (!mediaRecorder) return;
  mediaRecorder.stop();
  recording = false;
  refs.speakBtn?.classList.remove("recording");
  refs.speakBtn.textContent = "Speak";
  refs.input?.removeAttribute("disabled");
  setStatus("Uploading audio…");
}

async function uploadRecordedAudio(blob, ext) {
  try {
    const fd = new FormData();
    fd.append("audio", blob, `input.${ext}`);
    fd.append("sessionId", chatId);
    fd.append("email", session?.user?.email || "");
    fd.append("timestamp", new Date().toISOString());

    const res = await fetch(N8N_AUDIO_URL, {
      method: "POST",
      body: fd,
    });

    if (!res.ok) {
      const t = await res.text().catch(() => "");
      appendBubble("ai", "Upload failed — please try again.");
      setStatus(`Upload error ${res.status}.`, true);
      console.error("n8n upload failed:", t);
      return;
    }

    const ctype = (res.headers.get("content-type") || "").toLowerCase();

    if (ctype.includes("application/json")) {
      const data = await res.json().catch(() => ({}));
      if (data.audio_url) {
        appendAudioBubble("ai", data.audio_url, "AI reply (audio)");
      } else if (data.audio_base64) {
        const mime = data.mime || "audio/mpeg";
        const src = `data:${mime};base64,${data.audio_base64}`;
        appendAudioBubble("ai", src, "AI reply (audio)");
      } else {
        appendBubble("ai", data.message || "Received response, but no audio was provided.");
      }
    } else {
      const outBlob = await res.blob();
      const url = URL.createObjectURL(outBlob);
      appendAudioBubble("ai", url, "AI reply (audio)");
    }

    setStatus("Ready.");
  } catch (err) {
    console.error("uploadRecordedAudio error:", err);
    setStatus("Upload failed. Please try again.", true);
    appendBubble("ai", "Sorry — upload failed.");
  }
}

/* ------------------------------ bindings ------------------------------ */
function bindUI() {
  // chips -> fill input
  refs.chips.forEach((chip) => {
    chip.addEventListener("click", () => {
      const fill = chip.getAttribute("data-fill") || chip.textContent || "";
      if (refs.input) {
        refs.input.value = fill;
        refs.input.focus();
      }
    });
  });

  // send button
  refs.sendBtn?.addEventListener("click", handleSend);

  // Enter to send (Shift+Enter for newline if you switch to textarea later)
  refs.input?.addEventListener("keydown", (e) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  });

  // tools (stubs / routes)
  refs.callBtn?.addEventListener("click", () => {
    window.location.href = "call.html";
  });
  refs.filesBtn?.addEventListener("click", async () => {
    alert("Files: connect your upload flow here.");
  });

  // SPEAK toggle
  refs.speakBtn?.addEventListener("click", async () => {
    if (!recording) {
      await startRecording();
    } else {
      stopRecording();
    }
  });

  // history nav (hamburger)
  refs.hamburger?.addEventListener("click", () => {
    window.location.href = "history.html";
  });

  // logout
  refs.logoutBtn?.addEventListener("click", async () => {
    try {
      await supabase.auth.signOut();
    } catch (e) {
      console.warn("signOut error:", e);
    } finally {
      window.location.replace("/auth.html");
    }
  });
}

/* -------------------------------- boot -------------------------------- */
(async function boot() {
  await ensureAuthedOrRedirect();
  session = await getSession();
  bindUI();
  setStatus(session?.user ? "Signed in. How can I help?" : "Checking sign-in…");
})();
